{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking notebook\n",
    "\n",
    "This notebook contains all of the methods and analysis for performing benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook parameters\n",
    "These parameters are used throughout the notebook for benchmarking. These parameters include paths, tuning, and other various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_names = \"./abundance.tsv\"\n",
    "accession2taxid_file = \"../../database/krakenDB/taxonomy/nucl_gb.accession2taxid\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the NCBI to Tax id namings\n",
    "with open('out_dictionary.txt') as f:\n",
    "    dictionary_str = f.read()\n",
    "dictionary = json.loads(dictionary_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create mapping dictionary (don't need to run, done offline and included)\n",
    "This step is time consuminig so better done offline\n",
    "\n",
    "**NOTE**: This is skipped assuming the above works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_needed_ncbi_ids():\n",
    "    \"\"\"\n",
    "    gets NCBI ids\n",
    "    \"\"\"\n",
    "    file_with_names_opened = open(file_with_names)\n",
    "    \n",
    "    # grab all needed NCBI ids\n",
    "    ncbi_ids = []\n",
    "    line = file_with_names_opened.readline()\n",
    "    line_counter = 0\n",
    "    while(line):\n",
    "        if (line_counter > 0): # skip header\n",
    "            ncbi_id = line.split(\"\\t\")[0]\n",
    "            ncbi_ids.append(ncbi_id)\n",
    "        line = file_with_names_opened.readline()\n",
    "        line_counter += 1\n",
    "        \n",
    "    file_with_names_opened.close()\n",
    "    \n",
    "    return ncbi_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapping_dictionary():\n",
    "    \"\"\"\n",
    "    Creates dictionary for mapping NCBI ids to \n",
    "    taxonomy.\n",
    "    \n",
    "    Uses nucl_gb.accession2taxid\n",
    "    \n",
    "    NC_033618\tNC_033618.1\t1931113\t1139918407\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "\n",
    "    # grab taxid mappings\n",
    "    acc2tax_open = open(accession2taxid_file)\n",
    "    line = acc2tax_open.readline()\n",
    "    counter = 0\n",
    "    while(line):\n",
    "        line = acc2tax_open.readline()\n",
    "        line = line.split(\"\\t\")\n",
    "        accession = line[1]\n",
    "        taxid = line[2]\n",
    "        if accession in ncbi_ids:\n",
    "            dictionary[accession] = taxid\n",
    "        if (len(dictionary.keys()) == len(ncbi_ids)):\n",
    "            break\n",
    "        counter += 1\n",
    "        \n",
    "        if (counter % 100000 == 0):\n",
    "            print(f\"{counter} lines have been parsed \\n\")\n",
    "    acc2tax_open.close()\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "if not dictionary:\n",
    "    ncbi_ids = get_needed_ncbi_ids()\n",
    "    dictionary = create_mapping_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers\n",
    "These methods are used for parsing all of the tools being benchmarked. These parsers are passed to a general parser function, giving a strategy-pattern-like method for obtaining result from tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_enrichseq(enrichseq_dir: Path, delim=\",\"):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the enrichseq output directory.\n",
    "        \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a singular EnrichSeq output directory.\n",
    "        2. [optional; Def=','] - delimiter\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        Abundance Dictionary containing:\n",
    "            1. taxid abundances\n",
    "            abundances_dict = {'tax_id_1' : 33,\n",
    "                               'tax_id_2' : 33,\n",
    "                               ...,\n",
    "                               'tax_id_N' : 33,\n",
    "                              }\n",
    "            2. cluster abundances\n",
    "            abundances_dict = {'cluster_1' : 33,\n",
    "                               'cluster_2' : 33,\n",
    "                               ...,\n",
    "                               'cluster_M' : 33,\n",
    "                              }\n",
    "    \"\"\"\n",
    "    # nested dictionary of different abundance measurements\n",
    "    abundances = {\"taxid_abundance\" : {},\"cluster_abundance\" : {}} \n",
    "    # get paths\n",
    "    output_path = enrichseq_dir / Path('enrichseq/output_files/')\n",
    "    taxid_abundances_path = output_path / Path('taxid_abundances.csv')\n",
    "    cluster_abundances_path = output_path / Path('cluster_abundances.csv')\n",
    "    csvs_to_parse = {\"taxid_abundance\" : taxid_abundances_path, \n",
    "                     \"cluster_abundance\" : cluster_abundances_path}\n",
    "    # parse abundance CSVs\n",
    "    for csv_name, csv_file in csvs_to_parse.items():\n",
    "        with open(csv_file, \"r\") as csv_file_opened:\n",
    "            csv_file_lines = csv_file_opened.readlines() # never that big, read all into RAM\n",
    "            for line in csv_file_lines:\n",
    "                tax_clust_id, abundance_val = line.strip(\"\\n\").split(delim)\n",
    "                abundances[csv_name][tax_clust_id] = float(abundance_val)\n",
    "\n",
    "    return abundances\n",
    "\n",
    "def parser_fastviromeexplorer(directory, name_column=0, counts_column=3, delim=\"\\t\"):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the FastViromeExplorer output directory.\n",
    "        \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a singular FastViromeExplorer output directory.\n",
    "        2. column index corresponding to NCBI id\n",
    "        3. column index corresponding to the read counts\n",
    "        4. [optional; Def='\\t'] - delimiter\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        Abundance Dictionary containing:\n",
    "            1. taxid abundances\n",
    "            abundances_dict = {'tax_id_1' : 33,\n",
    "                               'tax_id_2' : 33,\n",
    "                               ...,\n",
    "                               'tax_id_N' : 33,\n",
    "                              }\n",
    "    \"\"\"\n",
    "    # init datastructures\n",
    "    abundances = {\"taxid_abundance\" : {}} # <tax/clust>id : abundance\n",
    "    # get paths\n",
    "    taxid_abundances = directory / Path('abundance.tsv')\n",
    "    # parse abundance CSVs\n",
    "    csvs_to_parse = {\"taxid_abundance\" : taxid_abundances}\n",
    "    total_abundance = 0\n",
    "    for csv_name, csv_file in csvs_to_parse.items():\n",
    "        with open(csv_file, \"r\") as csv_file_opened:\n",
    "            csv_file_lines = csv_file_opened.readlines() # never that big, read all into RAM\n",
    "            for line_ind, line in enumerate(csv_file_lines):\n",
    "                if line_ind > 0: # skip header\n",
    "                    ncbi_id = line.strip(\"\\n\").split(delim)[name_column]\n",
    "                    counts_val = line.strip(\"\\n\").split(delim)[counts_column]\n",
    "\n",
    "                    # convert NCBI name to taxid, save counts\n",
    "                    if ncbi_id in dictionary:\n",
    "                        tax_clust_id = dictionary[ncbi_id] # 'dictionary' imported above\n",
    "                    else:\n",
    "                        tax_clust_id = 'unk'\n",
    "                    abundances[csv_name][tax_clust_id] = float(counts_val)\n",
    "                    total_abundance += float(counts_val)\n",
    "    \n",
    "    # update abundances dictionary\n",
    "    ids_to_del = []\n",
    "    for tax_id, abundance_val in abundances[\"taxid_abundance\"].items():\n",
    "        if total_abundance > 0:\n",
    "            abundances[\"taxid_abundance\"][tax_id] /= total_abundance #normalize\n",
    "        if abundances[\"taxid_abundance\"][tax_id] < 0.001:\n",
    "            ids_to_del.append(tax_id)\n",
    "    # delete 0 value taxids\n",
    "    for val in ids_to_del:\n",
    "        del abundances[\"taxid_abundance\"][val]\n",
    "\n",
    "    return abundances\n",
    "\n",
    "def parse_simulated_fasta(fasta_path):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the simulated true fasta file used\n",
    "        for testing.\n",
    "        \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a singular simulated fasta file\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        Abundance Dictionary containing:\n",
    "            1. taxid abundances\n",
    "            abundances_dict = {'tax_id_1' : 33,\n",
    "                               'tax_id_2' : 33,\n",
    "                               ...,\n",
    "                               'tax_id_N' : 33,\n",
    "                              }\n",
    "    \"\"\"\n",
    "    abundances = {'taxid_abundance' : {}}\n",
    "    total_counts = 0\n",
    "    with open(fasta_path, \"r\") as fasta_opened:\n",
    "        line = fasta_opened.readline()\n",
    "        while (line):\n",
    "            if (line[0] == \">\"):\n",
    "                ncbi_id = line[1:].split(\"|\")[0].split(\"-\")[0]\n",
    "                # dictioinary from FastViromeExplorer, obtained above\n",
    "                if ncbi_id in dictionary:\n",
    "                    name = dictionary[line[1:].split(\"|\")[0].split(\"-\")[0]]\n",
    "                else:\n",
    "                    name = \"unk\"\n",
    "                # increment abundance level per read count\n",
    "                if name in abundances['taxid_abundance']:\n",
    "                    abundances['taxid_abundance'][name] += 1\n",
    "                else:\n",
    "                    abundances['taxid_abundance'][name] = 1\n",
    "                total_counts += 1\n",
    "                # print update\n",
    "                if (total_counts % 1000000 == 0):\n",
    "                    print(f\"{total_counts} lines parsed\")\n",
    "            line = fasta_opened.readline()\n",
    "            \n",
    "    #turn counts into abundances - normalize\n",
    "    for tax_id in abundances['taxid_abundance'].keys():\n",
    "        abundances['taxid_abundance'][tax_id] /= total_counts #normalize\n",
    "    return abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'taxid_abundance': {'2681618': 0.32963232138684007, '10868': 0.3339167091819126, '2886930': 0.3310543089373423}}\n",
      "{'taxid_abundance': {'2886930': 0.32134713471347137, 'UNK': 0.03574157415741574, '10868': 0.3215941594159416, '2681618': 0.32131713171317133}, 'cluster_abundance': {'C_2': 0.32134713471347137, 'UNK': 0.03574157415741574, 'C_1': 0.3215941594159416, 'C_3': 0.32131713171317133}}\n",
      "{'taxid_abundance': {'2886930': 0.3333333333333333, '10868': 0.3333333333333333, '2681618': 0.3333333333333333}}\n"
     ]
    }
   ],
   "source": [
    "# testing parsing functions\n",
    "\n",
    "# Paths\n",
    "fastvirome_test_dir = \"//scratch/summit/dral3008/benchmarking_enrichseq/results/FastViromeExplorer/num_mutations_test/3_genomes_sim_05del_05ins_illumina/\"\n",
    "enrichseq_test_dir = \"//scratch/summit/dral3008/benchmarking_enrichseq/results/enrichseq/num_mutations_test/3_genomes_sim_00del_05ins_illumina./\"\n",
    "truth_test_dir = \"//scratch/summit/dral3008/benchmarking_enrichseq/tests/num_mutations_test/3_genomes_sim_05del_05ins_illumina.fa\"\n",
    "# run tests\n",
    "fastvirome_values = parser_fastviromeexplorer(fastvirome_test_dir)\n",
    "enrichseq_values = parser_enrichseq(enrichseq_test_dir)\n",
    "true_values = parse_simulated_fasta(truth_test_dir)\n",
    "print(fastvirome_values)\n",
    "print(enrichseq_values)\n",
    "print(true_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Methods and structures\n",
    "The methods and data structures here are used for creating a common data structure for the output of all tools being compared with one another. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultStruct:\n",
    "    \"\"\" EnrichSeq - datastruct for holding results \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.l2_abundance_distance = []\n",
    "        self.classification_recall = 0\n",
    "        self.classification_precision = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARSERS_MAP = {\"enrichseq\" : parser_enrichseq,\n",
    "               \"FastViromeExplorer\" : parser_fastviromeexplorer,\n",
    "               \"truth\" : parse_simulated_fasta}\n",
    "\n",
    "def parse_dir(results_directory, test_directory, parsers=PARSERS_MAP):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses all of the result directories including\n",
    "        the test directory and returns a data structure containing the results.\n",
    "        \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a singular simulated fasta file\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        Abundance Dictionary containing:\n",
    "            1. taxid abundances\n",
    "            abundances_dict = {'tax_id_1' : 33,\n",
    "                               'tax_id_2' : 33,\n",
    "                               ...,\n",
    "                               'tax_id_N' : 33,\n",
    "                              }\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    # parse truth\n",
    "    results = parse_true_directory(test_directory, results, parsers)\n",
    "    # parse results\n",
    "    results = parse_tools(results_directory, results, parsers)\n",
    "    # create results from parsed information\n",
    "    results = parsed_dict_to_results(results)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def parse_true_directory(test_directory, results: Dict, parsers):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the truth directory, adding the parsed \n",
    "        abundance results to input results dictionary.\n",
    "        \n",
    "                    TEST\n",
    "                      |\n",
    "                    /   \\\n",
    "                TEST_1    TEST_2\n",
    "               /   |        |    \\\n",
    "       test-1.a test-1.b test-2.a test-2.b\n",
    "       \n",
    "                    into \n",
    "                       \n",
    "                   Results (a dictionary)\n",
    "                      |\n",
    "                    /   \\\n",
    "             \"TEST_1\"    \"TEST_2\"\n",
    "               /   |        |    \\\n",
    "    trueAb-1.a trueAb-1.b trueAb-2.a trueAb-2.b\n",
    "         \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a the entire truth test directory\n",
    "        2. results dictionary\n",
    "        3. parsers\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        results dictionary with the true abundance values added:\n",
    "        \n",
    "        example:\n",
    "        'num_genomes_test': {\n",
    "                             '5_genomes_sim_illumina': {'true': \n",
    "                                  {'taxid_abundance': {'2886930': 0.2, \n",
    "                                                       '10868': 0.2, \n",
    "                                                       '2681618': 0.2, \n",
    "                                                       '10658': 0.2, \n",
    "                                                       '127507': 0.2}\n",
    "                                  }\n",
    "                             },\n",
    "    \"\"\"\n",
    "    # parse truth\n",
    "    for test_directory_name in os.listdir(test_directory):\n",
    "        test_full_path = Path(test_directory) / Path(test_directory_name)\n",
    "        if os.path.isdir(test_full_path): # if directory\n",
    "            # create sub dictionary if not exists\n",
    "            if test_directory_name not in results: results[test_directory_name] = {}\n",
    "                \n",
    "            # loop through all fasta files and parse for true abundance\n",
    "            for file_test in os.listdir(test_full_path):\n",
    "                file_full_path = Path(test_full_path) / Path(file_test)\n",
    "                if os.path.isfile(file_full_path) and (file_full_path.suffix == \".fa\"): # if file and fasta\n",
    "                    #file_test = file_test.strip(\".fa\")\n",
    "                    # create subsub dictionary if not exists\n",
    "                    if file_test not in results[test_directory_name]:\n",
    "                        file_test = file_test.replace(\".fa\", \"\")\n",
    "                        results[test_directory_name][file_test] = {}\n",
    "                        \n",
    "                    # add abundances to results\n",
    "                    abundances = parsers[\"truth\"](file_full_path)\n",
    "                    results[test_directory_name][file_test][\"true\"] = abundances\n",
    "    return results\n",
    "                 \n",
    "    \n",
    "def parse_tools(results_directory, results: Dict, parsers):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the results directory, adding the \n",
    "        parsed abundances results to input results dictionary.  \n",
    "         \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a the entire benchmarking results directory\n",
    "        2. results dictionary\n",
    "        3. parsers\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        results dictionary with the tool prediction abundances \n",
    "        values added.\n",
    "        \n",
    "        example:\n",
    "        'num_genomes_test': {\n",
    "                             '5_genomes_sim_illumina': {tool_X': \n",
    "                                  {'taxid_abundance': {'2886930': 0.2, \n",
    "                                                       '10868': 0.2, \n",
    "                                                       '2681618': 0.2, \n",
    "                                                       '10658': 0.2, \n",
    "                                                       '127507': 0.2}\n",
    "                                  }\n",
    "                             },\n",
    "    \"\"\"\n",
    "    for tool_name in os.listdir(results_directory):\n",
    "        results_path = Path(results_directory) / Path(tool_name)\n",
    "        for test_directory_name in os.listdir(results_path):\n",
    "            test_full_path = Path(results_path) / Path(test_directory_name)\n",
    "            if os.path.isdir(test_full_path): # if directory\n",
    "                # loop through all fasta files and parse for true abundance\n",
    "                for file_test in os.listdir(test_full_path):\n",
    "                    file_full_path = Path(test_full_path) / Path(file_test)\n",
    "                    if os.path.isdir(file_full_path): # is results dir\n",
    "                        # add abundances to results\n",
    "                        try:\n",
    "                            abundances = parsers[tool_name](file_full_path)\n",
    "                            results[test_directory_name][file_test.strip(\".\")][tool_name] = abundances\n",
    "                        except:\n",
    "                            print(f\"{tool_name} is missing {file_test} from {test_directory_name}\")\n",
    "                            continue\n",
    "    return results\n",
    "\n",
    "def parsed_dict_to_results(results):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        This function parses the parsed results dictionary,\n",
    "        and creates a dictionary with all of the correct results.\n",
    "        Overall this utilizes the results structure.\n",
    "         \n",
    "    Input\n",
    "    -----------\n",
    "        1. Path to a results dictionary containing truth and \n",
    "           tool predictions\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        1. results dictionary with the tool results.\n",
    "    \"\"\"\n",
    "    for test_name in results.keys():\n",
    "        for sub_test in results[test_name].keys():\n",
    "            for tool_name, result_val in results[test_name][sub_test].items():\n",
    "#                 print(f\"{test_name}, {sub_test}, {tool_name}\")\n",
    "                if tool_name != \"true\":\n",
    "                    results_out = get_results(results[test_name][sub_test][tool_name], \n",
    "                                              results[test_name][sub_test][\"true\"])\n",
    "                    results[test_name][sub_test][tool_name] = results_out\n",
    "            del results[test_name][sub_test][\"true\"]\n",
    "    return results\n",
    "\n",
    "def get_results(predicted_results, true_results):\n",
    "    \"\"\"                          \n",
    "    Description\n",
    "    -----------\n",
    "        Given the true results and tool results, this\n",
    "        function returns a Result Struct for a given tool.\n",
    "        \n",
    "    **NOTE**: This is where all of the metrics are calculated\n",
    "              so this is the most important function for the \n",
    "              benchmarking - contains the logic.\n",
    "         \n",
    "    Input\n",
    "    -----------\n",
    "        1. dictionary of predicted results\n",
    "        2. dictionary of true results\n",
    "        \n",
    "    Output\n",
    "    -----------\n",
    "        1. ResultStruct() with the tool results.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    results_structure = ResultStruct()\n",
    "    predicted_abundances = predicted_results['taxid_abundance']\n",
    "    true_abundances = true_results['taxid_abundance']\n",
    "    \n",
    "    # error handling\n",
    "    if (len(true_abundances) == 0): \n",
    "        print(f\"TRUTH EMPTY\")\n",
    "        return results_structure\n",
    "    \n",
    "    # classification results\n",
    "    ## true positives\n",
    "    true_positives = []\n",
    "    for pred_taxid in predicted_abundances.keys():\n",
    "        if pred_taxid in true_abundances.keys():\n",
    "            true_positives.append(pred_taxid)\n",
    "    ## false positives\n",
    "    false_positives = []\n",
    "    for pred_taxid in predicted_abundances.keys():\n",
    "        if (pred_taxid not in true_abundances.keys()) and (pred_taxid != \"UNK\"):\n",
    "            false_positives.append(pred_taxid)\n",
    "    ## false negatives\n",
    "    false_negatives = []\n",
    "    for pred_taxid in true_abundances.keys():\n",
    "        if pred_taxid not in predicted_abundances.keys():\n",
    "            false_negatives.append(pred_taxid)\n",
    "            \n",
    "    ## get metrics\n",
    "#     print(f\"predicted_abundances = {predicted_abundances}, true abundaces = {true_abundances}\")\n",
    "    recall = len(true_positives) / (len(true_positives) + len(false_negatives))\n",
    "    precision = len(true_positives) / (len(true_positives) + len(false_positives))\n",
    "#     print(f\"recall : {recall} | precision : {precision}\")\n",
    "    \n",
    "    # abundance results\n",
    "    ## L2 distances\n",
    "    l2_dist_array = []\n",
    "    total_abundance_wo_unk = sum([abundance for key, abundance in predicted_abundances.items() if key != \"UNK\" ])\n",
    "    for tax_id, pred_abundance in predicted_abundances.items():\n",
    "        if tax_id in true_abundances:\n",
    "            pred_abundance /= total_abundance_wo_unk\n",
    "            l2_diff = abs(pred_abundance - true_abundances[tax_id])\n",
    "        else:\n",
    "            l2_diff = 0\n",
    "        l2_dist_array.append(l2_diff)\n",
    "    \n",
    "    # store into results structure\n",
    "    results_structure.l2_abundance_distance = l2_dist_array\n",
    "    results_structure.classification_recall = recall\n",
    "    results_structure.classification_precision = precision\n",
    "    \n",
    "    return results_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "2000000 lines parsed\n",
      "3000000 lines parsed\n",
      "4000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n",
      "2000000 lines parsed\n",
      "3000000 lines parsed\n",
      "4000000 lines parsed\n",
      "5000000 lines parsed\n",
      "6000000 lines parsed\n",
      "7000000 lines parsed\n",
      "8000000 lines parsed\n",
      "9000000 lines parsed\n",
      "1000000 lines parsed\n",
      "1000000 lines parsed\n"
     ]
    }
   ],
   "source": [
    "# create 'results'\n",
    "results = parse_dir(\"//scratch/summit/dral3008/benchmarking_enrichseq/results/\",\n",
    "                    \"//scratch/summit/dral3008/benchmarking_enrichseq/tests/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Methods\n",
    "These methods use the common `ResultStruct` datastructure (or arry thereof) for plotting individual tool metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_barplot(input_results, test, metric='classification'):                                                        \n",
    "    \"\"\"                                                                         \n",
    "    This function plots a bar plot output for a given test set and value\n",
    "    \"\"\" \n",
    "    \n",
    "    width = 0.35\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    if (metric == 'classification'):\n",
    "        sub_results = input_results[test]\n",
    "        x_tick_names = [[], []]\n",
    "        x_tick_arr = []\n",
    "        index_map = {'enrichseq' : 0, 'FastViromeExplorer' : 1}\n",
    "        for subtest_name in sub_results.keys():\n",
    "            x_tick_arr.append(\" \".join(subtest_name.split(\"_\")))\n",
    "            for tool, results_struct in sub_results[subtest_name].items():\n",
    "                print(f\"Recall: {results_struct.classification_recall}\")\n",
    "                print(f\"Precision: {results_struct.classification_precision}\")\n",
    "                f1_score = 2 * (results_struct.classification_recall * results_struct.classification_precision) \n",
    "                if ((results_struct.classification_recall != 0) or\n",
    "                    (results_struct.classification_precision != 0)):\n",
    "                    f1_score /= (results_struct.classification_recall + results_struct.classification_precision) \n",
    "                x_tick_names[index_map[tool]].append(f1_score)\n",
    "                \n",
    "        # make plot\n",
    "        ind = np.arange(len(x_tick_names[0]))\n",
    "        ax.bar(ind, x_tick_names[index_map['enrichseq']], color='r', width = 0.30)\n",
    "        if (len(x_tick_names[0]) == len(x_tick_names[1])):\n",
    "            ax.bar(ind + 0.30, x_tick_names[index_map['FastViromeExplorer']], width = 0.30, color='b')\n",
    "        ax.legend(labels=['enrichseq', 'FastViromeExplorer'])\n",
    "        ax.set_xticks(ind + 0.25)\n",
    "        ax.set_xticklabels(x_tick_arr, rotation=90)\n",
    "        ax.set_title(f\"Testing the impact of {test} \\n {metric}-focused\", size=15)\n",
    "        ax.set_ylabel(\"F1 score\", size=15)\n",
    "        ax.set_xlabel(\"Sub test\", size=15)\n",
    "        \n",
    "        \n",
    "    elif (metric == 'abundance'):\n",
    "        sub_results = input_results[test]\n",
    "        x_tick_names = [[], []]\n",
    "        x_tick_arr = []\n",
    "        index_map = {'enrichseq' : 0, 'FastViromeExplorer' : 1}\n",
    "        for subtest_name in sub_results.keys():\n",
    "            x_tick_arr.append(\" \".join(subtest_name.split(\"_\")))\n",
    "            for tool, results_struct in sub_results[subtest_name].items():\n",
    "                l2_avg = np.average(results_struct.l2_abundance_distance)\n",
    "                x_tick_names[index_map[tool]].append(l2_avg)\n",
    "                \n",
    "        # make plot\n",
    "        ind = np.arange(len(x_tick_names[0]))\n",
    "        ax.bar(ind, x_tick_names[index_map['enrichseq']], color='r', width = 0.30)\n",
    "        if (len(x_tick_names[0]) == len(x_tick_names[1])):\n",
    "            ax.bar(ind + 0.30, x_tick_names[index_map['FastViromeExplorer']], width = 0.30, color='b')\n",
    "        ax.legend(labels=['enrichseq', 'FastViromeExplorer'])\n",
    "        ax.set_xticks(ind + 0.25)\n",
    "        ax.set_xticklabels(x_tick_arr, rotation=90)\n",
    "        ax.set_title(f\"Testing the impact of {test} \\n {metric}-focused\", size=15)\n",
    "        ax.set_ylabel(\"L2 distance\", size=15)\n",
    "        ax.set_xlabel(\"Sub test\", size=15)\n",
    "    else:\n",
    "        print(f\"Metric of type {metric} is not known\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "This section splits the various benchmarking sections into a clear, concise set of scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of genomes comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot(results, test='num_genomes_test', metric='classification')\n",
    "plot_barplot(results, test='num_genomes_test', metric='abundance')\n",
    "\n",
    "results['num_genomes_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of read mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot(results, test='num_mutations_test', metric='classification')\n",
    "plot_barplot(results, test='num_mutations_test', metric='abundance')\n",
    "\n",
    "results['num_mutations_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barplot(results, test='num_reads_test', metric='classification')\n",
    "plot_barplot(results, test='num_reads_test', metric='abundance')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
